{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 15 In-Class Assignment: Diagonalization\n",
    "\n",
    "<img alt=\"Classig equation for diagonalizing a matrix. Will be discussed in class\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/62ab0ef52ecb1e1452efe6acf096923035c75f62\" width=\"50%\">\n",
    "\n",
    "Image from: [https://en.wikipedia.org/wiki/Diagonalizable_matrix](https://en.wikipedia.org/wiki/Diagonalizable_matrix)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda for today's class (80 minutes)\n",
    "\n",
    "1. [(20 minutes) Pre-class Assignment Review](#Pre-class_Assignment_Review)\n",
    "1. [(20 minutes) Diagonalization](#Diagonalization)\n",
    "1. [(20 minutes) The Power of a Matrix](#The_Power_of_a_Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "sym.init_printing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Pre-class_Assignment_Review\"></a>\n",
    "## 1. Pre-class Assignment Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [15--Diagonalization_pre-class-assignment.ipynb](15--Diagonalization_pre-class-assignment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name=\"Diagonalization\"></a>\n",
    "## 2. Diagonalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Reminder_**: The eigenvalues of triangular (upper and lower) and diagonal matrices are easy:\n",
    "\n",
    "* The eigenvalues for triangular matrices are the diagonal elements.\n",
    "* The eigenvalues for the diagonal matrices are the diagonal elements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonalization\n",
    "\n",
    "\n",
    "**Definition**: A square matrix $A$ is said to be *diagonalizable* if there exist a matrix $C$ such that $D=C^{-1}AC$ is a diagonal matrix.\n",
    "\n",
    "**Definition**: $B$ is a *similar matrix* of $A$ if we can find $C$ such that $B=C^{-1}AC$.\n",
    "\n",
    "\n",
    "Given an $n\\times n$ matrix $A$, can we find another $n \\times n$ invertable matrix $C$ such that when $D=C^{-1}AC$ is diagonal, i.e., $A$ is diagonalizable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because $C$ is inveritble, we have \n",
    "$$C^{-1}AC=D \\\\ CC^{-1}AC = CD\\\\ AC = CD $$\n",
    "\n",
    "\n",
    "* Generate $C$ as the columns of $n$ linearly independent vectors $(x_1...x_n)$ We can compute $AC=CD$ as follows:\n",
    "$$ A\\begin{bmatrix} \\vdots  & \\vdots  & \\vdots  & \\vdots  \\\\ \\vdots  & \\vdots  & \\vdots  & \\vdots  \\\\ { x }_{ 1 } & { x }_{ 2 } & \\dots  & { x }_{ n } \\\\ \\vdots  & \\vdots  & \\vdots  & \\vdots  \\end{bmatrix}=AC=CD=\\begin{bmatrix} \\vdots  & \\vdots  & \\vdots  & \\vdots  \\\\ \\vdots  & \\vdots  & \\vdots  & \\vdots  \\\\ { x }_{ 1 } & { x }_{ 2 } & \\dots  & { x }_{ n } \\\\ \\vdots  & \\vdots  & \\vdots  & \\vdots  \\end{bmatrix}\\begin{bmatrix} { \\lambda  }_{ 1 } & 0 & 0 & 0 \\\\ 0 & { \\lambda  }_{ 2 } & 0 & 0 \\\\ \\vdots  & \\vdots  & { \\dots  } & \\vdots  \\\\ 0 & 0 & 0 & { \\lambda  }_{ n } \\end{bmatrix}$$\n",
    "* Then we check the corresponding columns of the both sides. We have \n",
    "$$Ax_1 = \\lambda_1x_1\\\\\\vdots\\\\Ax_n=\\lambda x_n$$\n",
    "\n",
    "* $A$ has $n$ linear independent eigenvectors.\n",
    "\n",
    "* $A$ is saied to be *similar* to the diagonal matrix $D$, and the transformation of $A$ into $D$ is called a *similarity transformation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple example\n",
    "\n",
    "Consider the following:\n",
    "$$ A = \\begin{bmatrix}7& -10\\\\3& -4\\end{bmatrix},\\quad C = \\begin{bmatrix}2& 5\\\\1& 3\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>Do this:</font>** Find the similar matrix $D = C^{-1}AC$ of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your answer to the above question here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3cdb9915439d45fe",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "\n",
    "checkanswer.matrix(D, '8313fe0f529090d6a8cdb36248cfdd6c');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>Do this:</font>** Find the eigenvalues and eigenvectors of $A$. Set variables ```e1``` and ```vec1``` to be the smallest eigenvalue and it's associated eigenvector and ```e2, vec2``` to represent the  largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your answer to the above question here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f4fda102502f50f9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.float(e1, \"e4c2e8edac362acab7123654b9e73432\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-88300f29b8aec498",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.float(e2, \"d1bd83a33f1a841ab7fda32449746cc4\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f26e2f5a3e41bdd8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.eq_vector(vec1, \"d28f0a721eedb3d5a4c714744883932e\", decimal_accuracy = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a0ef501c592a3fcc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.eq_vector(vec2, \"09d9df5806bc8ef975074779da1f1023\", decimal_accuracy = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem:** Similar matrices have the same eigenvalues.\n",
    "\n",
    "**Proof:** Assume $B=C^{-1}AC$ is a similar matrix of $A$, and $\\lambda$ is an eigenvalue of $A$ with corresponding eigenvector $x$. That is, $$Ax=\\lambda x$$ \n",
    "Then we have $$B(C^{-1}x) = C^{-1}AC(C^{-1}x) = C^{-1}Ax = C^{-1}(\\lambda x)= \\lambda (C^{-1}x).$$\n",
    "That is $C^{-1}x$ is an eigenvector of $B$ with eigenvalue $\\lambda$.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second example\n",
    "\n",
    "&#9989;  **<font color=red>Do this:</font>** Consider \n",
    "$$ A = \\begin{bmatrix}-4& -6\\\\3& 5\\end{bmatrix}.$$\n",
    "Find a matrix $C$ such that $C^{-1}AC$ is diagonal. (Hint, use the function `diagonalize` in `sympy`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your answer to the above question here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d9c7ff4aa895199e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Check the output type\n",
    "assert(type(C)==sym.Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2c06b41f80b7a258",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.matrix(C,'ba963b7fef354b4a7ddd880ca4bac071')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The third example\n",
    "\n",
    "&#9989;  **<font color=red>Do this:</font>** Consider \n",
    "$$ A = \\begin{bmatrix}5& -3\\\\3& -1\\end{bmatrix}.$$\n",
    "Can we find a matrix $C$ such that $C^{-1}AC$ is diagonal?  (Hint: find eigenvalues and eigenvectors using `sympy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8eb9fd1f4a5a6136",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Put your answer to the above question here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions of eigenspaces and diagonalization\n",
    "\n",
    "**Definition**: The set of all eigenvectors of a $n\\times n$ matrix corresponding to a eigenvalue $\\lambda$, together with the zero vector, is a subspace of $R^n$. This subspace spaces is called *eigenspace*.\n",
    "\n",
    "* For the third example, we have that the characteristic equation $(\\lambda-2)^2=0$.\n",
    "* Eigenvalue $\\lambda=2$ has multiplicity 2, but the eigenspace has dimension 1, since we can not find two lineare independent eigenvector for $\\lambda =2$. \n",
    "\n",
    "> The dimension of an eigenspace of a matrix is less than or equal to the multiplicity of the corresponding eigenvalue as a root of the characteristic equation.\n",
    "\n",
    "> A matrix is diagonalizable if and only if the dimension of every eigenspace is equal to the multiplicity of the corresponding eigenvalue as a root of the characteristic equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fourth example\n",
    "\n",
    "&#9989;  **<font color=red>Do this:</font>** Consider \n",
    "$$ A = \\begin{bmatrix}2& -1\\\\1& 2\\end{bmatrix}.$$\n",
    "Can we find a matrix $C$ such that $C^{-1}AC$ is diagonal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3bc59d8f51537cae",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Put your answer to the above question here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"The_Power_of_a_Matrix\"></a>\n",
    "## 3. The Power of a Matrix\n",
    "\n",
    "* For a diagonalizable matrix $A$, we have $C^{-1}AC=D$. Then we have \n",
    "$$A = C D C^{-1}$$\n",
    "* We have \n",
    "$$A^2 = C D C^{-1} C D C^{-1} = C D^2 C^{-1}$$\n",
    "$$A^n = C D C^{-1} \\dots C D C^{-1} = C D^n C^{-1}$$\n",
    "* Because the columns of $C$ are eigenvectors, so we can say that the eigenvectors for $A$ and $A^n$ are the same if $A$ is diagonalizable. \n",
    "* If $x$ is an eigenvector of $A$ with the corresponding eigenvalue $\\lambda$, then $x$ is also an eigenvector of $A^n$ with the corresponding eigenvalue $\\lambda^n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some libraries you may need to use\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "sym.init_printing(use_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Random Walk\n",
    "\n",
    "* Define the following matrices:\n",
    "    * $I$ is the identity matrix\n",
    "    * $A$ is the adjacency matrix\n",
    "    * $D$ is diagonal matrix of degrees (number of edges connected to each node)\n",
    "    \n",
    "$$W=\\frac{1}{2}(I + AD^{-1})$$\n",
    "\n",
    "* The **lazy random walk matrix**, $W$, takes a distribution vector of *stuff*, $p_{t}$, and diffuses it to its neighbors:\n",
    "\n",
    "$$p_{t+1}=Wp_{t}$$\n",
    "\n",
    "* For some initial distribution of *stuff*, $p_{0}$, we can compute how much of it would be at each node at time, $t$, by powering $W$ as follows:\n",
    "\n",
    "$$p_{t}=W^{t}p_{0}$$\n",
    "\n",
    "* Plugging in the above expression yields:\n",
    "\n",
    "$$p_{t}=\\left( \\frac{1}{2}(I+AD^{-1}) \\right)^t p_{0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>DO THIS</font>**: Using matrix algebra, show that $\\frac{1}{2}(I + AD^{-1})$ is **similar** to  $I-\\frac{1}{2}N$, where $N=D^{-\\frac{1}{2}}(D-A)D^{-\\frac{1}{2}}$ is the normalized graph Laplacian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1a93e034adef3eb1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Your answer goes here** (follow along after attempting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Walk on Barbell Graph\n",
    "\n",
    "To generate the barbell graph, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 60 # number of nodes\n",
    "B = nx.Graph() # initialize graph\n",
    "\n",
    "## initialize empty edge lists\n",
    "edge_list_complete_1 = [] \n",
    "edge_list_complete_2 = []\n",
    "edge_list_path = []\n",
    "\n",
    "## generate node lists\n",
    "node_list_complete_1 = np.arange(int(n/3))\n",
    "node_list_complete_2 = np.arange(int(2*n/3),n)\n",
    "node_list_path = np.arange(int(n/3)-1,int(2*n/3))\n",
    "\n",
    "## generate edge sets for barbell graph\n",
    "for u in node_list_complete_1:\n",
    "    for v in np.arange(u+1,int(n/3)):\n",
    "        edge_list_complete_1.append((u,v))\n",
    "        \n",
    "for u in node_list_complete_2:\n",
    "    for v in np.arange(u+1,n):\n",
    "        edge_list_complete_2.append((u,v))\n",
    "\n",
    "for u in node_list_path:\n",
    "    edge_list_path.append((u,u+1))\n",
    "\n",
    "# G.remove_edges_from([(3,0),(5,7),(0,7),(3,5)])\n",
    "\n",
    "## add edges\n",
    "B.add_edges_from(edge_list_complete_1)\n",
    "B.add_edges_from(edge_list_complete_2)\n",
    "B.add_edges_from(edge_list_path)\n",
    "\n",
    "\n",
    "## draw graph\n",
    "pos=nx.spring_layout(B) # positions for all nodes\n",
    "\n",
    "### nodes\n",
    "nx.draw_networkx_nodes(B,pos,\n",
    "                       nodelist=list(node_list_complete_1),\n",
    "                       node_color='c',\n",
    "                       node_size=400,\n",
    "                       alpha=0.8)\n",
    "nx.draw_networkx_nodes(B,pos,\n",
    "                       nodelist=list(node_list_path),\n",
    "                       node_color='g',\n",
    "                       node_size=200,\n",
    "                       alpha=0.8)\n",
    "nx.draw_networkx_nodes(B,pos,\n",
    "                       nodelist=list(node_list_complete_2),\n",
    "                       node_color='b',\n",
    "                       node_size=400,\n",
    "                       alpha=0.8)\n",
    "\n",
    "\n",
    "### edges\n",
    "nx.draw_networkx_edges(B,pos,\n",
    "                       edgelist=edge_list_complete_1,\n",
    "                       width=2,alpha=0.5,edge_color='c')\n",
    "nx.draw_networkx_edges(B,pos,\n",
    "                       edgelist=edge_list_path,\n",
    "                       width=3,alpha=0.5,edge_color='g')\n",
    "nx.draw_networkx_edges(B,pos,\n",
    "                       edgelist=edge_list_complete_2,\n",
    "                       width=2,alpha=0.5,edge_color='b')\n",
    "\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show() # display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>Do this</font>:** Generate the lazy random walk matrix, $W$, for the above graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = nx.adjacency_matrix(B)\n",
    "A = A.todense()\n",
    "\n",
    "d = np.sum(A,0) # Make a vector of the sums.\n",
    "D = np.diag(np.asarray(d)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your answer to the above question here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fb79da016761443e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from answercheck import checkanswer\n",
    "checkanswer.matrix(W, \"7af4a5b11892da6e1a605c8239b62093\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>Do this</font>:** Compute the eigenvalues and eigenvectors of $W$. Make a diagonal matrix $J$ with the eigenvalues on the diagonal. Name the matrix of eigenvectors $V$ (each column is an eigenvector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your answer to the above question here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make sure we constructed $V$ and $A$ correctly by double checking that $W = VJV^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(W, V*J*np.linalg.inv(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989;  **<font color=red>Do this</font>:** Let your $p_{0}=[1,0,0,\\ldots,0]$. Compute $p_{t}$ for $t=1,2,\\ldots,100$, and plot $||v_{1}-p_{t}||_{1}$ versus $t$, where $v_{1}$ is the eigenvector associated with the largest eigenvalue $\\lambda_{1}=1$ and whose sum equals 1. (**Note**: $||\\cdot||_{1}$ may be computed using ```np.linalg.norm(v_1-p_t, 1)```.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9e691ac811c35e4d",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Put your answer to the above question here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to Complete Graph\n",
    "\n",
    "If you complete the above, do the same for a complete graph on the same number of nodes.\n",
    "\n",
    "&#9989;  **<font color=red>Question</font>:** What do you notice about the graph that is different from that above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9cadbdd3014757bc",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Put your answer to the above question here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Written by Dr. Dirk Colbry, Michigan State University\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
